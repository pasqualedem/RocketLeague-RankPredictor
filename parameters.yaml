experiment: Basic Preprocess -- 22 classes
models:
  dummy:
    strategy: ['uniform', 'most_frequent']
  linear:
    penalty: ['l2']
  naive_bayes:
    var_smoothing: [1e-9]
  random_forest:
    n_estimators: [10, 100]
    criterion: ['gini', 'entropy']
    class_weight: [None, 'balanced']
    parallelization: [0, 0, 2]
  xgbclassifier:
    n_estimators: [10, 100]
    eta: [0.01, 0.1, 0.2, 0.3]
    parallelization: [0, 0, 8]
  knn:
    n_neighbors: [3]
    parallelization: [0, 0, 8]
  mlpclassifier:
    hidden_layer_sizes: [[128, 64, 32]]
    alpha: [0,001, 0.0001, 0.00001]
    batch_size: [256]
    random_state: [42]
    verbose: [True]
    early_stopping: [True]
    learning_rate_init: [0.01, 0.001]

data:
  path: 'data/preprocessed/dataset_selected.csv'
  target: 'tier'